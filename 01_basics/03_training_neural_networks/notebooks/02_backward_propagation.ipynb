{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a052eb",
   "metadata": {},
   "source": [
    "# Introduction to Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcdefc",
   "metadata": {},
   "source": [
    "## Training Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61378be1",
   "metadata": {},
   "source": [
    "- **Initialize Weights and Biases:** These values control how the network initially processes information\n",
    "\n",
    "- **Forward-Pass:** Pass the input through the network to get an output (discussed in forward_propagation)\n",
    "\n",
    "- **Calculate the Error:** Compare the network’s output to the correct answer to measure the difference\n",
    "\n",
    "- **Back-Propagation:** Use the loss value to adjust the weights and biases to improve the network’s accuracy\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/training_phases.png\" alt=\"training phases visual\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5feca8f",
   "metadata": {},
   "source": [
    "## Back-Propagation Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc08a1",
   "metadata": {},
   "source": [
    "- The network uses the **loss** to adjust its **weights** and **biases** through a process known as **backpropagation**\n",
    "- Backpropagation calculates **how much weights should change** to reduce the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95efaf",
   "metadata": {},
   "source": [
    "## Problem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc00ee5",
   "metadata": {},
   "source": [
    "- **Given:**  \n",
    "    The architecture of the network\n",
    "    - Count of layers\n",
    "    - Count of neurons of each layer\n",
    "    - Activation function\n",
    "\n",
    "- **Training Data**  \n",
    "    A set of input-output pairs:\n",
    "    $$(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\cdots , (x^{(N)}, y^{(N)})$$\n",
    "\n",
    "- We want the function $f$:\n",
    "    - Consider a neural network as a parametric function $f(x;w)$\n",
    "\n",
    "- We need a **loss function** to show how penalizes obtained output $f(x;w)$ when the desired output is $y$:\n",
    "$$E(W) = \\frac{1}{N} \\sum_{n=1}^N loss \\left(f(x^{(n)};w), y^{(n)} \\right)$$\n",
    "\n",
    "- **Minimize** the **cost function**\n",
    "$$\\hat{W} = \\argmin_{W} E(W)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96a3fc",
   "metadata": {},
   "source": [
    "# Optimization Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ff87f",
   "metadata": {},
   "source": [
    "## Wight Update Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c90d77",
   "metadata": {},
   "source": [
    "**Random Search:**\n",
    "- Tries values randomly\n",
    "- Inefficient and impractical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b412c",
   "metadata": {},
   "source": [
    "**Gradient Descent:**\n",
    "- Follows the slope of the loss function\n",
    "- Efficient and guided\n",
    "\n",
    "**Why Gradient Descent?**\n",
    "- It updates weights by following the slope, reducing error with each step.\n",
    "- Controlled, stepwise updates ensure we move closer to minimizing the loss effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c90f2c",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf4779",
   "metadata": {},
   "source": [
    "**Gradient Descent**\n",
    "\n",
    "In each step, takes steps proportional to the negate of teh gradient descent vector of the current point.\n",
    "\n",
    "$$w^{(t+1)} = w^t - \\gamma_t \\nabla_w J(w^t)$$\n",
    "$$\\nabla_w J(w^t) = [\\frac{\\partial{J(w)}}{\\partial{w_1}}, \\frac{\\partial{J(w)}}{\\partial{w_2}}, ..., \\frac{\\partial{J(w)}}{\\partial{w_d}}]$$\n",
    "\n",
    "Where:\n",
    "- $w^t$ is the current point.\n",
    "- $\\gamma_t$ is step size *(learning rate parameter)*.\n",
    "    - If $\\gamma_t$ is small enough, then $J(w^{(t+1)}) \\le J(w^{(t)})$\n",
    "    - When $\\gamma$ is too small: gradient descent can be slow.\n",
    "    - When $\\gamma$ is too large: gradient descent can overshoot the minimum. May fail to converge or diverge.\n",
    "- $J(w)$ decreases from $w^t$ in the direction of $-\\gamma_t \\nabla_w J(w^t)$.\n",
    "- **Assumption**: $J(w)$ is defined and differentiable in a neighborhood of a point $w^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55328bb",
   "metadata": {},
   "source": [
    "Since Gradient Descent is better, here is some properties that help to use gradient descent effectively:\n",
    "\n",
    "\n",
    "- Define **differentiable loss** or divergence between the output of the network and the desired output for the training instances\n",
    "    - And a total error, which is the average divergence over all training instances\n",
    "- Use **continuous activation functions** to enables us to estimate network parameters\n",
    "- Optimize network parameters to **minimize the total error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2060ca9c",
   "metadata": {},
   "source": [
    "# Weight Initialization Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e07d5",
   "metadata": {},
   "source": [
    "## Importance of Proper Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07d0ff",
   "metadata": {},
   "source": [
    "- Proper initialization ensures:\n",
    "    - Faster **convergence**\n",
    "    - Improves **training stability**\n",
    "- Prevents issues like\n",
    "    - **Vanishing gradients:**\n",
    "        - Gradients becomes extremely **small**\n",
    "        - Updates are **negligible**\n",
    "        - Network learns very **slowly or not at all**\n",
    "    - **Exploding gradients:**\n",
    "        - Gradients becomes extremely **large**\n",
    "        - Updates are too drastic\n",
    "        - **Unstable** network training\n",
    "\n",
    "**Question:** How can we initialize weights to maximize learning efficiency and prevent gradient problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4966153",
   "metadata": {},
   "source": [
    "## Initialization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a5a99",
   "metadata": {},
   "source": [
    "### **Zero Initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68375e5",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "- Set all weights to zero.\n",
    "\n",
    "**Key Points:**\n",
    "- Rarely used\n",
    "- Leads to identical updates for all neurons\n",
    "- Preventing the network from learning distinct features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7517d7",
   "metadata": {},
   "source": [
    "### **Random Initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffc0e8",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "- Assign **small random** values to weights.\n",
    "\n",
    "**Distribution:**\n",
    "- Typically, weights are initialized using a **uniform** or **normal** distribution:\n",
    "$$w \\approx u(-\\epsilon, \\epsilon) \\quad \\text{or} \\quad w \\approx N(0, \\sigma^2)$$\n",
    "\n",
    "**Key Points:**\n",
    "- **Break symmetry:**\n",
    "    - If all weights are initialized to the same value (e.g., zeros), every neuron in a layer learns the exact same thing during training (no progress!).\n",
    "    - Random initialization breaks this symmetry by giving each neuron a slightly different starting point.\n",
    "\n",
    "- Still cause issues with **gradient magnitudes**.\n",
    "    - If $\\sigma^2$ is too **small** $\\rightarrow$ **Vanishing gradients**\n",
    "    - If $\\sigma^2$ is too **large** $\\rightarrow$ **exploding gradients**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475fb91",
   "metadata": {},
   "source": [
    "### **Xavier Initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcce308",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "- Xavier Initialization is designed to **keep the variance of activations consistent** across layers, ideal for **sigmoid** and **tanh** activations.\n",
    "\n",
    "**Objective:**\n",
    "- Prevents the **vanishing** or **exploding** of signal magnitudes during forward and backward propagation.\n",
    "\n",
    "**Condition:**\n",
    "$$\\frac{1}{N_l} var[w] = 1$$\n",
    "Where:\n",
    "- $n_l$: Number of neurons in layer $l$\n",
    "\n",
    "**Initialization Scheme:**\n",
    "$$w \\approx u(- \\sqrt{\\frac{1}{n_l}}, \\sqrt{\\frac{1}{n_l}})$$\n",
    "\n",
    "**Key Points**\n",
    "- **Balancing Variance**\n",
    "    - If a layer has **many inputs**, make the **weights smaller** (to **avoid exploding** signals).\n",
    "    - If a layer has **few inputs**, make the **weights larger** (to **avoid vanishing** signals).\n",
    "- Initialize weights so that the variance of activations and variance of gradients remain roughly the same across layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb199c12",
   "metadata": {},
   "source": [
    "**Note:**  \n",
    "This formula is a special case of Xavier initialization.  \n",
    "The full Xavier formula for uniform distribution is:\n",
    "$$w \\approx u(- \\sqrt{\\frac{6}{n_{in} + n_{out}}}, \\sqrt{\\frac{6}{n_{in} + n_{out}}})$$\n",
    "if $n_{in} = n_{out} = n_l$, simplifying to:\n",
    "$$w \\approx u(- \\sqrt{\\frac{1}{n_l}}, \\sqrt{\\frac{1}{n_l}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d285d",
   "metadata": {},
   "source": [
    "### **He Initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e9c93",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "- He Initialization (or Kaiming Initialization) is designed for neural networks with **ReLU** activations, considering the non-linearity of these functions.\n",
    "\n",
    "**Objective:**\n",
    "- Aims to prevent the **exponential growth** or **reduction** of input signal magnitudes through layers.\n",
    "\n",
    "**Condition:**\n",
    "$$\\frac{1}{2} n_l Var[w] = 1$$\n",
    "\n",
    "**Initialization Scheme:**\n",
    "$$w_l \\approx N(0, \\frac{2}{n_l})$$\n",
    "\n",
    "**Key Points**\n",
    "- ReLU discards half the signals: For any negative input, the output is zero.\n",
    "    - **Xavier**'s scaling factor ($\\frac{1}{n_l}$) is **too small**, causing gradients to **vanish** over time.\n",
    "- This implies a **zero-centered Gaussian** distribution with a standard deviation of $\\frac{2}{n_l}$, where biases are initialized to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f832bd8",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8ff5a",
   "metadata": {},
   "source": [
    "## Importance of Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47053f80",
   "metadata": {},
   "source": [
    "**Why Transform Outputs?**  \n",
    "**Raw outputs** need to be transformed into **meaningful values**, such as probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77b6d5",
   "metadata": {},
   "source": [
    "Choose activation function that makes the neuron\n",
    "- **Differentiable**\n",
    "- **Non-zero derivatives** over much of the input space\n",
    "    - Because Training network with zero gradient will not guide us to the optimum cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4cdda",
   "metadata": {},
   "source": [
    "## Common Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e197e",
   "metadata": {},
   "source": [
    "### **Step Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf78567",
   "metadata": {},
   "source": [
    "**Formula:**\n",
    "$$\n",
    "\\text{Step}(z) = \\begin{cases}\n",
    "1 & \\text{if } z \\ge 0 \\\\ \n",
    "0 & \\text{if } z \\lt 0\n",
    "\\end{cases}\n",
    "$$\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"../assets/step_function.png\" alt=\"step function\">\n",
    "</div>\n",
    "  \n",
    "- Not differentiable at $z=0$\n",
    "- Derivative is $0$ elsewhere $\\implies$ **Not suitable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badac30c",
   "metadata": {},
   "source": [
    "### **Sigmoid**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15984f04",
   "metadata": {},
   "source": [
    "**Formula:**\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad \\text{Where: } z = \\sum_i w_ix_i + b$$\n",
    "\n",
    "**Derivative:**\n",
    "$$\\sigma(z)' = \\sigma(z) (1 - \\sigma(z))$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/sigmoid.png\" alt=\"sigmoid function\">\n",
    "</div>\n",
    "\n",
    "**Advantages:**\n",
    "- Squashes the input between 0 and 1, which makes it useful in **probabilistic interpretations** (e.g., logistic regression).\n",
    "- Often used in output layers for **binary classification** problems.\n",
    "- **Smooth** & **Differentiable**\n",
    "\n",
    "**Limitations:**\n",
    "- **Gradient Saturation:** When $z$ is very large or very small, the gradient becomes nearly zero, causing **slow learning** (**vanishing** gradient problem).\n",
    "- **Not Zero-Centered:** The output is not zero-centered, which can make optimization more difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301d123",
   "metadata": {},
   "source": [
    "### **Soft-Max**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa9bde",
   "metadata": {},
   "source": [
    "Soft-max vector activation is often used at the output of multi-class classifier networks to convert raw outputs to probabilities for each class:\n",
    "$$\n",
    "o_i = \\frac{\\exp(z_i)}{\\sum_j \\exp(z_j)}, \\quad \\text{where } z_i = \\sum_j w_{ji} x_j + b_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $o_i$: Probability $P(y = i | x)$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/soft_max.png\" alt=\"applying soft-max function\">\n",
    "  </div>\n",
    "\n",
    "**Key Points:**\n",
    "- Soft-max is used in the output layer for **multi-class classification**\n",
    "- It converts **logits** (raw unbounded numerical scores) into a **probability distribution** across classes.\n",
    "- The class with the **highest probability** is **selected** as the prediction.\n",
    "- It ensures all outputs sum to 1, making it ideal for choosing one class out of multiple options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a489dc7",
   "metadata": {},
   "source": [
    "### **Hyperbolic Tangent (Tanh)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8b544",
   "metadata": {},
   "source": [
    "**Formula:**\n",
    "$$\\text{Tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/tanh_activation.png\" alt=\"Tanh function\">\n",
    "</div>\n",
    "\n",
    "**Advantages:**\n",
    "- **Zero-Centered:** Output ranges from -1 to 1, making optimization easier. (Balanced Updates $\\rightarrow$ Reduced Bias in Gradient Descent $\\rightarrow$ Faster Convergence)\n",
    "- Better for **hidden layers** than Sigmoid due to **zero-centered** output.\n",
    "\n",
    "**Limitations:**\n",
    "- Similar **saturation issues** as Sigmoid: **Large input** values push **gradients towards zero** (**vanishing** gradient problem).\n",
    "\n",
    "**Tanh vs. Sigmoid**\n",
    "- The derivative of the Tanh function has a much **steeper slope** at $x = 0$, meaning it provides a **larger gradient** for backpropagation compared to the Sigmoid function.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/tanh_vs_sigmoid.png\" alt=\"Tanh vs Sigmoid function\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39c55c",
   "metadata": {},
   "source": [
    "### **ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f978a",
   "metadata": {},
   "source": [
    "**Formula:**\n",
    "$$\\text{ReLU}(z) = \\max(0, z)$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/basic_relu.png\" alt=\"basic ReLU function\">\n",
    "</div>\n",
    "\n",
    "**Advantages of ReLU**\n",
    "- **Faster convergence**: Specially for **deep** network\n",
    "- Does not saturate positive values, helping to **avoid vanishing** gradient problem\n",
    "- **Computationally efficient** (Simpler than Sigmoid/Tanh)\n",
    "\n",
    "**Limitation:**\n",
    "- **Dead ReLU Problem:** Neurons can become inactive during training, outputting 0 for all inputs if they receive negative values consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e102a",
   "metadata": {},
   "source": [
    "### **Leaky ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960b3d8",
   "metadata": {},
   "source": [
    "Allows a small, non-zero gradient for negative inputs.\n",
    "$$\\text{LeakyReLU}(z) = \\max(\\alpha z, z), \\quad \\alpha = 0.01$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/leaky_relu.png\" alt=\"leaky relu function\">\n",
    "</div>\n",
    "\n",
    "**Advantages:**\n",
    "- Similar to ReLU\n",
    "- Helps prevent the **dead ReLU** problem, where neurons stop updating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eaa35b",
   "metadata": {},
   "source": [
    "**Parametric ReLU (PReLU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4f12e",
   "metadata": {},
   "source": [
    "Similar to Leaky ReLU, but the slope for negative inputs $\\alpha$ is **learned** during training.\n",
    "$$\\text{PReLU}(z) = \\max(\\alpha z, z), \\quad \\text{$\\alpha$ is learned}$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/prelu.png\" alt=\"parametric ReLU function\">\n",
    "</div>\n",
    "\n",
    "**Advantages:**\n",
    "- Provides more flexibility by adjusting the slope for negative inputs based on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5956196",
   "metadata": {},
   "source": [
    "### **Exponential Linear Unit (ELU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b3447",
   "metadata": {},
   "source": [
    "**Similar to ReLU for positive** values but **smoother for negative** inputs.\n",
    "\n",
    "$$\n",
    "\\text{ELU}(z) = \\begin{cases}\n",
    "z & \\text{if } z \\gt 0 \\\\ \n",
    "\\alpha(e^z - 1) & \\text{if } z \\le 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/elu.png\" alt=\"ELU function\">\n",
    "</div>\n",
    "\n",
    "**Advantages:**\n",
    "- Provides **faster convergence** and **reduces bias** shift by smoothing negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61ae5e",
   "metadata": {},
   "source": [
    "### **Soft-Plus**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb18fdc",
   "metadata": {},
   "source": [
    "SoftPlus is a **smooth approximation** to the ReLU function and can be used to constrain the output of a machine to always be **positive**.\n",
    "$$\\text{Softplus}(z) = \\ln(1 + e^z)$$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/soft_plus.png\" alt=\"soft-plus function\">\n",
    "</div>\n",
    "\n",
    "**Advantages:**\n",
    "- The output is always positive\n",
    "- The function smoothly increases and is **always differentiable**, **unlike ReLU** (sharp corner at zero)\n",
    "- For **negative** inputs, the function **approaches zero**, but unlike ReLU, it never exactly reaches zero, **avoiding the problem of dying neurons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13bba7",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462aefff",
   "metadata": {},
   "source": [
    "## Regression Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a83bc",
   "metadata": {},
   "source": [
    "### **Sum of Squared Errors (SSE) & Mean Squared Error (MSE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c2bde",
   "metadata": {},
   "source": [
    "**SSE**\n",
    "\n",
    "Also known as $L_2$ divergence\n",
    "\n",
    "For real-valued output vectors (regression problems).\n",
    "\n",
    "Squared Euclidean distance between true and desired outout:\n",
    "$$\n",
    "loss(y, o) = \\frac{1}{2} \\|y - o \\|^2 = \\frac{1}{2} \\sum_k (y_k - o_k)^2\n",
    "$$\n",
    "\n",
    "**Mean Squared Error (MSE)**\n",
    "$$MSE = \\frac{1}{N} SSE$$\n",
    "\n",
    "**Note:** This is differentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3df8d",
   "metadata": {},
   "source": [
    "### **Mean Absolute Error (MAE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c9717",
   "metadata": {},
   "source": [
    "For real-valued output vectors (regression problems).\n",
    "\n",
    "Absolute Euclidean distance between true and desired outout:\n",
    "$$\n",
    "loss(y, o) = \\frac{1}{N} \\sum_k |y_k - o_k|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b64b4a",
   "metadata": {},
   "source": [
    "### **MSE vs. MAE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec103c3",
   "metadata": {},
   "source": [
    "**MSE (Mean Squared Error):**\n",
    "- Heavily **penalizes large errors**, promoting smoother outputs.\n",
    "- Its quadratic gradient leads to **faster convergence** for **large errors**, but it can be **sensitive to outliers**.\n",
    "\n",
    "**MAE (Mean Absolute Error):**\n",
    "- Treats all **errors uniformly**, resulting in sharper outputs and **better handling of outliers**.\n",
    "- Its constant gradient **ensures stable optimization** but can **slow convergence** with **large errors**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd138c",
   "metadata": {},
   "source": [
    "## Classification Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff72444",
   "metadata": {},
   "source": [
    "### **Binary Classification (Logistic Regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1e416",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "**Sigmoid Function:**\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad \\text{Where: } z = \\sum_i w_ix_i + b$$\n",
    "\n",
    "For classification problems:\n",
    "$$P(Y = 1 | X) = \\frac{1}{1 + \\exp(- \\sum_i w_ix_i - b)}$$\n",
    "\n",
    "This the perceptron with a sigmoid activation\n",
    "    - It actually computes the probability that the input belongs to class 1\n",
    "\n",
    "If the desired **output is a binary**, Output activation typically is a **sigmoid**\n",
    "- Viewed as a probability $P(Y = c | x)$ of class $c$\n",
    "- Differentiable\n",
    "\n",
    "**Binary Classifier:**\n",
    "\n",
    "For binary classifier with scalar output $o \\in (0, 1)$:\n",
    "$$\n",
    "loss(y, o) = -y \\log(o) - (1 - y)\\log(1- o)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433692e2",
   "metadata": {},
   "source": [
    "### **Multi-Class Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc63f1a",
   "metadata": {},
   "source": [
    "**Multi-Class Classifier**\n",
    "\n",
    "Multi-class classifier with $K$ classes, the one-hot representation for the desired output $y$\n",
    "- ($K-1$ zeros and a single $1$)\n",
    "\n",
    "The network's output will be a probability vector\n",
    "- $K$ probability values that sum to $1$\n",
    "\n",
    "**Soft-Max Activation Function:**\n",
    "\n",
    "Soft-max vector activation is often used at the output of multi-class classifier networks:\n",
    "$$\n",
    "o_i = \\frac{\\exp(z_i)}{\\sum_j \\exp(z_j)}, \\quad \\text{where } z_i = \\sum_j w_{ji} x_j + b_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $o_i$: Probability $P(class = i | x)$\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"../assets/soft_max.png\" alt=\"applying soft-max function\">\n",
    "  </div>\n",
    "\n",
    "If the desired **output is a multinomial**, Output activation typically is a **soft-max**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af6d0d",
   "metadata": {},
   "source": [
    "**Cost function:**\n",
    "\n",
    "Desired output $y$ is one-hot vector $[0, 0, \\cdots, 1, \\cdots, 0, 0]^T$ with the 1 in the $c$-th position(for class $c$)\n",
    "\n",
    "Actual output will be probability distribution $[o_1, o_2, \\cdots, o_K]^T$\n",
    "\n",
    "The **cross-entropy** between the desired one-hot output and **actual class $c$**\n",
    "$$\n",
    "loss(y, o) = \\sum_{i=1}^K y_i \\log(o_i) = - \\log(o_c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2328a05",
   "metadata": {},
   "source": [
    "## Probabilistic View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c36b7",
   "metadata": {},
   "source": [
    "### **Likelihood and Log-Likelihood Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180f30e",
   "metadata": {},
   "source": [
    "**Likelihood:**\n",
    "$$\n",
    "p(y^{(1)}, y^{(2)}, \\cdots, y^{(N)} | x^{(1)}, x^{(2)}, \\cdots, x^{(N)}) = \\prod_{n=1}^N p(y^{(n)} | x^{(n)}) = \\prod_{n=1}^N p \\left(y^{(n)} | f(x^{(n)}; W) \\right)\n",
    "$$\n",
    "\n",
    "**Log-Likelihood:**\n",
    "$$\n",
    "\\log \\prod_{n=1}^N p \\left(y^{(n)} | f(x^{(n)}; W) \\right) = \\sum_{n=1}^N \\log \\left(p \\left(y^{(n)} | f(x^{(n)}; W) \\right) \\right)\n",
    "$$\n",
    "\n",
    "Maximizing likelihood corresponds to loss function $Loss = - \\log \\left(p \\left(y^{(n)} | f(x^{(n)}; W) \\right) \\right)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b075291",
   "metadata": {},
   "source": [
    "### **Probabilistic Modeling for Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586dcbb",
   "metadata": {},
   "source": [
    "Assume $y$ given $x$ follows a  Gaussian (Normal) distribution:\n",
    "$$p(y|x) = N(f(x;w), \\sigma^2)$$\n",
    "This is equivalent to writing:\n",
    "$$y = f(x;w) + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "That means:\n",
    "- For a fixed $x$, $y$ is normally distributed\n",
    "- Mean = $f(x; w)$\n",
    "- Variance = $\\sigma^2$\n",
    "\n",
    "We model the uncertainty in the predictions:\n",
    "$$p(y|x,w,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{1}{2\\sigma^2}(y - f(x;w))^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24c92b",
   "metadata": {},
   "source": [
    "**Apply MLE**\n",
    "\n",
    "Recall: The likelihood of parameters $w$ and $\\sigma^2$\n",
    "$$L(D;w,\\sigma^2) = \\prod_{i=1}^n p(y^{(i)} | x^{(i)}, w, \\sigma^2)$$\n",
    "\n",
    "The goal is to find:\n",
    "$$\\hat w = \\argmax_{w}L(D;w,\\sigma^2)$$\n",
    "\n",
    "It is easier to maximize the log-likelihood instead:\n",
    "$$\\hat w = \\argmax_{w} \\ln L(D;w,\\sigma^2)$$\n",
    "\n",
    "$$\\ln L(D;w,\\sigma^2) = \\ln \\prod_{i=1}^n p(y^{(i)} | x^{(i)}, w, \\sigma^2) = \\sum_{i=1}^n \\ln p(y^{(i)} | x^{(i)}, w, \\sigma^2)$$\n",
    "\n",
    "Substitute the Gaussian formula:\n",
    "$$\\ln p(y^{(i)} | x^{(i)}, w, \\sigma^2) = -\\ln \\sigma - \\frac{1}{2}\\ln 2\\pi - \\frac{1}{2\\sigma^2} (y^{(i)} - f(x^{(i)};w))^2$$\n",
    "\n",
    "Then the full log-likelihood becomes:\n",
    "$$\\ln L(D;w,\\sigma^2) = -n \\ln \\sigma - \\frac{n}{2}\\ln 2\\pi - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y^{(i)} - f(x^{(i)};w))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2b944",
   "metadata": {},
   "source": [
    "**MLE for $w$**\n",
    "\n",
    "The Goal is:\n",
    "$$\\hat w = \\argmax_{w} \\ln L(D;w,\\sigma^2) = -n \\ln \\sigma - \\frac{n}{2}\\ln 2\\pi - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y^{(i)} - f(x^{(i)};w))^2$$\n",
    "\n",
    "Which is the same as:\n",
    "$$\\hat w = \\argmin_{w} \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y^{(i)} - f(x^{(i)};w))^2$$\n",
    "\n",
    "This is exactly the minimizing **Sum of Squared Errors (SSE)**.  \n",
    "The standard objective in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c6a67",
   "metadata": {},
   "source": [
    "### **Probabilistic Modeling of Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601230e",
   "metadata": {},
   "source": [
    "#### **Binary Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc3f93",
   "metadata": {},
   "source": [
    "**Maximum Log Likelihood:**\n",
    "$$\\hat{w} = \\argmax_w \\log \\left(\\prod_{i=1}^N p(y^{(i)} | f(x^{(i)}, W))\\right) = \\argmax_w \\sum_{i=1}^N \\log \\left(p(y^{(i)} | f(x^{(i)}, W)) \\right)$$\n",
    "\n",
    "**Bernoulli Model**  \n",
    "- For binary classification:\n",
    "$$\n",
    "p(y^{(i)} | f(x^{(i)}, W)) = \n",
    "\\begin{cases} \n",
    "f(x^{(i)};W) & \\text{if } y^{(i)} = 1 \\\\\n",
    "1 - f(x^{(i)};W) & \\text{if } y^{(i)} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "- Concept Form:\n",
    "$$p(y^{(i)} | f(x^{(i)}, W)) = f(x^{(i)};W)^{y^{(i)}} (1 - f(x^{(i)};W))^{(1 - y^{(i)})}$$\n",
    "\n",
    "**Substitute In MLE formula:**\n",
    "$$\\log \\left(p(y^{(i)} | f(x^{(i)}, W))\\right) = \\sum_{i=1}^N \\left[y^{(i)}\\log \\left(f(x^{(i)};W)\\right) + (1 - y^{(i)}) \\log\\left(1 - f(x^{(i)};W)\\right) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d77dc",
   "metadata": {},
   "source": [
    "**Cost Function**\n",
    "**Cost Function: Negative Likelihood**\n",
    "\n",
    "To convert maximization to minimization:\n",
    "$$J(w) = -\\sum_{i=1}^N \\log \\left(p(y^{(i)} | f(x^{(i)}, W)) \\right)$$\n",
    "$$ = \\sum_{i=1}^N - y^{(i)}\\log \\left(f(x^{(i)};W)\\right) - (1 - y^{(i)}) \\log \\left(1 - f(x^{(i)};W)\\right)$$\n",
    "\n",
    "So:\n",
    "$$\\hat{w} = \\argmin_w J(w)$$\n",
    "\n",
    "**Key Properties:**\n",
    "- No Closed form solution for $\\nabla_wJ(w) = 0$  \n",
    "- However $J(w)$ is **convex** and has global minimum.\n",
    "- Solution Method: Use iterative optimization (e.g., gradient descent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0306b3a",
   "metadata": {},
   "source": [
    "#### **Multi-Class Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82e1e7",
   "metadata": {},
   "source": [
    "**Recall Multinomial Distribution:**\n",
    "\n",
    "Parameter Definition:\n",
    "$$\\theta = [\\theta_1, \\theta_2, ..., \\theta_K]$$\n",
    "Where:\n",
    "$$\\theta_k \\in [0, 1] \\quad \\text{and} \\quad \\sum_{k=1}^{K} \\theta_k = 1$$\n",
    "$$\\theta_k = p(x_k = 1)$$\n",
    "\n",
    "Likelihood:\n",
    "$$P(x|\\theta) = \\prod_{k=1}^K \\theta_k^{x_k} = \\theta_j \\quad \\text{(when $x_j = 1$)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5bd46",
   "metadata": {},
   "source": [
    "Set **cost function** as **negative of log likelihood**.\n",
    "\n",
    "We need $\\hat{W} = \\argmin_W J(W)$\n",
    "\n",
    "$$J(W) = -\\log\\prod_{i=1}^Np(y^{(i)} | x^{(i)}, W)$$\n",
    "$$ = -\\log \\prod_{i=1}^N \\prod_{k=1}^K f_k(x^{(i)};W)^{{y_k}^{(i)}}$$\n",
    "$$ = -\\log \\sum_{i=1}^N \\sum_{k=1}^K {{y_k}^{(i)}}\\log \\left(f_k(x^{(i)};W)\\right)$$\n",
    "\n",
    "There is no closed-form solution for $\\hat{W}$.  \n",
    "Use iterative optimization instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c099d",
   "metadata": {},
   "source": [
    "# Cross Entropy Loss & KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee79bb",
   "metadata": {},
   "source": [
    "**Cross Entropy Loss**\n",
    "\n",
    "Cost Function in classification problems\n",
    "\n",
    "**Kullback–Leibler Divergence Formula:**\n",
    "$$D_{KL}[q \\| p] = \\int{q(z) \\log \\left(\\frac{q(z)}{p(z)} \\right) dz} = \\int{q(z) \\log \\left(q(z) \\right) dz} - \\int{q(z) \\log \\left(p(z) \\right) dz}$$\n",
    "Also:\n",
    "$$D_{KL}[y \\| o] = \\sum_{k=1}^K q(z) \\log \\left(\\frac{q(z)}{p(z)} \\right) = \\sum_{k=1}^K q(z) \\log \\left(q(z) \\right) - \\sum_{k=1}^K q(z) \\log \\left(p(z) \\right)$$\n",
    "\n",
    "For multi-class classification problem:\n",
    "- $q(y | x)$: One-hot vector shows the target class of $x$\n",
    "- $p_{\\theta}(y | x)$: Outout of the parametric model\n",
    "\n",
    "Divergence between $y = [y_1, \\cdots, y_K]$ and $o = [o_1, \\cdots, o_K]$:\n",
    "$$D_{KL}[y \\| o] = \\sum_{k=1}^K q(z) \\log \\left(\\frac{q(z)}{p(z)} \\right) = 0 - \\sum_{k=1}^K y_k \\log \\left(p_{\\theta}(y = k | x) \\right)$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
